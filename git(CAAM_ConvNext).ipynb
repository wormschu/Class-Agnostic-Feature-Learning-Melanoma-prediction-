{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6062e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        model = models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1)\n",
    "        self.feature_extractor = torch.nn.Sequential(*list(model.features.children()))\n",
    "        \n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        cam_features = self.feature_extractor(x)\n",
    "        features = self.gap(cam_features)\n",
    "        features = features.view(x.shape[0], -1)\n",
    "        logits = self.classifier(features)\n",
    "        return logits,cam_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b296753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/439 [00:00<?, ?it/s]C:\\Users\\yonsei\\anaconda3\\envs\\worms\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: Train CE1 Loss: 0.2387, Train CE2 Loss: 0.3357, Train CAAM Loss: 0.0237, Acc: 0.9071 | Val CE1 Loss: 0.3086, Val CE2 Loss: 0.3582, Val CAAM Loss: 0.0143, Acc: 0.8555\n",
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002: Train CE1 Loss: 0.1651, Train CE2 Loss: 0.2850, Train CAAM Loss: 0.0152, Acc: 0.9393 | Val CE1 Loss: 0.3157, Val CE2 Loss: 0.3381, Val CAAM Loss: 0.0109, Acc: 0.8994\n",
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003: Train CE1 Loss: 0.1087, Train CE2 Loss: 0.2390, Train CAAM Loss: 0.0122, Acc: 0.9621 | Val CE1 Loss: 0.3727, Val CE2 Loss: 0.3836, Val CAAM Loss: 0.0098, Acc: 0.8213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 185\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m    184\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m--> 185\u001b[0m     train_loss1,train_loss2, train_loss3,train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mdo_epoch2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptm_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptm_2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "Cell \u001b[1;32mIn[3], line 117\u001b[0m, in \u001b[0;36mdo_epoch2\u001b[1;34m(model, dataloader, criterion1, criterion2, optim1, optim2)\u001b[0m\n\u001b[0;32m    115\u001b[0m optim1\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    116\u001b[0m optim2\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 117\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m optim1\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    119\u001b[0m optim2\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\worms\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\worms\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def min_max_normalize(image):\n",
    "    min_value,_ = torch.min(image, 1)\n",
    "    min_value,_ = torch.min(min_value, 1)\n",
    "    min_value = min_value.unsqueeze(1).unsqueeze(1)\n",
    "    max_value,_ = torch.max(image, 1)\n",
    "    max_value,_ = torch.max(max_value, 1)\n",
    "    max_value = max_value.unsqueeze(1).unsqueeze(1)\n",
    "    \n",
    "    output = (image - min_value) / (max_value - min_value)\n",
    "    \n",
    "    return output\n",
    "\n",
    "class CustomDataset:\n",
    "    def __init__(self, all_json, transform):\n",
    "        self.all_json = all_json\n",
    "        self.transform = transform\n",
    "        self.basedir = r'C:\\Users\\yonsei\\Desktop\\melanoma sex difeerence\\ISIC_2019_Training_Input\\resize/'\n",
    "        self.label_dict = {\"NV\": 0, \"MEL\": 1}\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.basedir + self.all_json[idx]['image'] + '.jpg'\n",
    "        image = self.transform(Image.open(img_path).convert(\"RGB\"))\n",
    "        label = self.label_dict[self.all_json[idx]['label']]\n",
    "        return image, image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_json)\n",
    "\n",
    "\n",
    "def do_epoch1(model, dataloader, criterion, optim=None):\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "\n",
    "    for x, _, y_true in tqdm(dataloader, leave=False):\n",
    "        x, y_true = x.to(device), y_true.to(device)\n",
    "        y_pred, _ = model(x)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "\n",
    "        if optim is not None:\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += (y_pred.argmax(dim=1) == y_true).float().mean().item()\n",
    "\n",
    "    mean_loss = total_loss / len(dataloader)\n",
    "    mean_accuracy = total_accuracy / len(dataloader)\n",
    "    return mean_loss, mean_accuracy\n",
    "\n",
    "\n",
    "def do_epoch2(model, dataloader, criterion1, criterion2, optim1=None, optim2=None):\n",
    "    total_ce1_loss = 0\n",
    "    total_ce2_loss = 0\n",
    "    total_caam_loss = 0\n",
    "    total_accuracy = 0\n",
    "    count = 0\n",
    "\n",
    "    for x1, x2, y_true in tqdm(dataloader, leave=False):\n",
    "        x1, x2, y_true = x1.to(device), x2.to(device), y_true.to(device)\n",
    "        seed = random.randint(1,1000)\n",
    "        \n",
    "        # 1. Cross-Entropy Loss1 (original input)\n",
    "        y_pred, feature_map = model(x1)\n",
    "        feature_map = F.relu(feature_map)\n",
    "        ce1_loss = criterion1(y_pred, y_true)\n",
    "\n",
    "        # 2. CAAM Loss\n",
    "        cam = min_max_normalize(torch.sum(feature_map, dim=1))\n",
    "        \n",
    "        transform_HF =  transforms.RandomHorizontalFlip()\n",
    "        transform_VF =  transforms.RandomVerticalFlip()\n",
    "        transform_random_crop =  transforms.RandomCrop(random.randint(160,210))\n",
    "        transform_resize = transforms.Resize(224)\n",
    "\n",
    "        ori_caam = transform_resize(cam)\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        # transformed ori-caam\n",
    "        caam = transform_resize(transform_VF(transform_HF(transform_random_crop(ori_caam))))\n",
    "        \n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        transform_x = transform_resize(transform_VF(transform_HF(transform_random_crop(x2))))\n",
    "        ty_pred,transform_feature_map = model(transform_x)\n",
    "        transform_feature_map = F.relu(transform_feature_map)\n",
    "        \n",
    "        # transformed caam\n",
    "        transform_caam = transform_resize(min_max_normalize(torch.sum(transform_feature_map, dim=1)))\n",
    "        \n",
    "        caam_loss = criterion2(transform_caam, caam)\n",
    "        \n",
    "        # 3. Cross-Entropy Loss2 ( input)\n",
    "        ce2_loss = criterion1(ty_pred, y_true)\n",
    "        \n",
    "        loss = ce1_loss + caam_loss + ce2_loss\n",
    "        \n",
    "        if optim1 is not None:\n",
    "            optim1.zero_grad()\n",
    "            optim2.zero_grad()\n",
    "            loss.backward()\n",
    "            optim1.step()\n",
    "            optim2.step()\n",
    "        \n",
    "        total_ce1_loss += ce1_loss.item()\n",
    "        total_ce2_loss += ce2_loss.item()\n",
    "        total_caam_loss += caam_loss.item()\n",
    "        total_accuracy += (y_pred.argmax(dim=1) == y_true).float().mean().item()\n",
    "        count += 1\n",
    "\n",
    "    mean_ce1_loss = total_ce1_loss / count\n",
    "    mean_ce2_loss = total_ce2_loss / count\n",
    "    mean_caam_loss = total_caam_loss / count\n",
    "    mean_accuracy = total_accuracy / count\n",
    "    return mean_ce1_loss, mean_ce2_loss, mean_caam_loss, mean_accuracy\n",
    "\n",
    "\n",
    "# Initialize device, data, and model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "with open(\"./Train.pkl\", \"rb\") as f:\n",
    "    train_set = pickle.load(f)\n",
    "with open(\"./Valid.pkl\", \"rb\") as f:\n",
    "    val_set = pickle.load(f)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                                   transforms.ToTensor()\n",
    "                                   ,transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "train_dataset = CustomDataset(train_set, transform)\n",
    "val_dataset = CustomDataset(val_set, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# class weight\n",
    "numoflabel_1 = 0\n",
    "numoflabel_2 = 0\n",
    "for i in range(len(train_set)):\n",
    "    if train_set[i]['label'] == \"NV\":\n",
    "        numoflabel_1 +=1\n",
    "    elif train_set[i]['label'] == \"MEL\":\n",
    "        numoflabel_2 +=1\n",
    "        \n",
    "weights = torch.tensor([numoflabel_1,numoflabel_2], dtype=torch.float32)\n",
    "weights = weights / weights.sum()\n",
    "weights = 1.0 / weights\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "model = Net().to(device)\n",
    "optim = torch.optim.Adam(model.parameters(),lr=5e-5)\n",
    "optm_1 = torch.optim.Adam(model.feature_extractor.parameters(), lr=1e-4)\n",
    "optm_2 = torch.optim.Adam(model.classifier.parameters(), lr=1e-5)\n",
    "\n",
    "lr_schedule1 = torch.optim.lr_scheduler.ReduceLROnPlateau(optm_1, patience=10, verbose=True)\n",
    "lr_schedule2 = torch.optim.lr_scheduler.ReduceLROnPlateau(optm_2, patience=10, verbose=True)\n",
    "\n",
    "criterion1 = nn.CrossEntropyLoss(weight=weights.to(device))\n",
    "criterion2 = nn.MSELoss()\n",
    "best_loss = 99999999\n",
    "# Initial 2-epoch training (do_epoch1)\n",
    "for epoch in range(1, 3):\n",
    "    model.train()\n",
    "    train_loss, train_accuracy = do_epoch1(model, train_loader, criterion1, optim=optim)\n",
    "\n",
    "for epoch in range(1, 100):\n",
    "    model.train()\n",
    "    train_loss1,train_loss2, train_loss3,train_accuracy = do_epoch2(model, train_loader, criterion1, criterion2, optim1 = optm_1, optim2 = optm_2)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss1,val_loss2, val_loss3,val_accuracy = do_epoch2(model, val_loader, criterion1, criterion2)\n",
    "        \n",
    "    print(f\"Epoch {epoch:03d}: Train CE1 Loss: {train_loss1:.4f}, Train CE2 Loss: {train_loss2:.4f}, Train CAAM Loss: {train_loss3:.4f}, Acc: {train_accuracy:.4f} | \"\n",
    "          f\"Val CE1 Loss: {val_loss1:.4f}, Val CE2 Loss: {val_loss2:.4f}, Val CAAM Loss: {val_loss3:.4f}, Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "    if val_loss1 + val_loss2 + val_loss3 < best_loss:\n",
    "        print('Saving model...')\n",
    "        best_loss = val_loss1 + val_loss2 + val_loss3 \n",
    "        torch.save(model.state_dict(), './GIT.pt')\n",
    "\n",
    "    lr_schedule1.step(val_loss2)\n",
    "    lr_schedule2.step(val_loss1 + val_loss3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc737a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4090",
   "language": "python",
   "name": "worms"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
